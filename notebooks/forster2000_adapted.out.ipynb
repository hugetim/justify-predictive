{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forster (2000) adapted"
   ],
   "id": "31e0657c-762c-44e2-b74f-b9df39ec332c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import math\n",
    "from functools import partial\n",
    "from typing import Iterable, Callable, Optional\n",
    "from numbers import Number"
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define prediction class"
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionTask:\n",
    "    def __init__(self, input, outcome=None):\n",
    "        self.A = input\n",
    "        self.B = outcome\n",
    "\n",
    "\n",
    "class WeightedPredictionClass:\n",
    "    def __init__(self, tasks: Iterable[PredictionTask], weights: Optional[Iterable[Number]] = None):\n",
    "        self.tasks = tasks\n",
    "        for task in self.tasks:\n",
    "            if task.B is None:\n",
    "                raise ValueError(\"All WeightedPredictionClass task outcomes must be known.\")\n",
    "        J = len(tasks)\n",
    "        if weights is not None:\n",
    "            if len(weights) != J:\n",
    "                raise ValueError(f\"len(weights), {len(weights)}, must equal len(tasks), {J}\")\n",
    "            self.weights = np.array(weights) / sum(weights)\n",
    "        else:\n",
    "            self.weights = np.ones(J)/J\n",
    "\n",
    "    def predictive_success(self, predicted_log_likelihood: Callable[[PredictionTask], float]) -> float:\n",
    "        return sum(w * predicted_log_likelihood(task) \n",
    "                   for w, task in zip(self.weights, self.tasks)\n",
    "                   if task.B is not None)"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_x(x_range, step=0.1, copies=20):\n",
    "    x_values = np.round(np.arange(x_range[0], x_range[1] + step, step), decimals=1)\n",
    "    repeated_x_values = np.tile(x_values, copies)\n",
    "    return np.sort(repeated_x_values)\n",
    "\n",
    "\n",
    "def generate_y(x, noise_std=0.0):\n",
    "    \"\"\"Generates data based on the specified model.\"\"\"\n",
    "    y = 0.5 + 0.5 * np.tanh(x - 2)\n",
    "    if noise_std:\n",
    "        y += np.random.normal(0, noise_std, size=len(x))\n",
    "    return y"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for replicability\n",
    "seed = sum(ord(char) for char in \"Rumpelstiltskin\")\n",
    "np.random.seed(seed)\n",
    "\n",
    "x0 = generate_x((0, 3.5), copies=20)\n",
    "y_known = generate_y(x0, noise_std=0.05)\n",
    "df = pd.DataFrame({'x': x0, 'y': y_known})\n",
    "\n",
    "\n",
    "def make_task(in_range, out_range) -> PredictionTask:\n",
    "    x_known = df[(df['x'] >= in_range[0]) & (df['x'] <= in_range[1])]['x'].values\n",
    "    y_known = df[(df['x'] >= in_range[0]) & (df['x'] <= in_range[1])]['y'].values\n",
    "    x_to_predict = df[(df['x'] >= out_range[0]) & (df['x'] <= out_range[1])]['x'].values\n",
    "    y_to_predict = df[(df['x'] >= out_range[0]) & (df['x'] <= out_range[1])]['y'].values\n",
    "    return PredictionTask(\n",
    "        dict(x_known=x_known,\n",
    "             y_known=y_known,\n",
    "             x_to_predict=x_to_predict,\n",
    "        ),\n",
    "        y_to_predict,\n",
    "    )"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "task_of_interest = make_task((0, 3.5), (3.6, 5))\n",
    "plt.scatter(task_of_interest.A['x_known'], task_of_interest.A['y_known'], label=\"TRUE\", \n",
    "            color=\"blue\", marker='s', s=10, alpha=0.1)\n",
    "plt.xlim(-0.075, 5.075)\n",
    "#plt.ylim(-0.2, 1.2)\n",
    "plt.show()"
   ],
   "id": "cell-fig-known-data"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_single = WeightedPredictionClass([make_task((0, 2.5), (2.6, 3.5))])"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define predictive methods"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(y_pred, y, sigma2) -> float:\n",
    "    \"\"\"Average log-likelihood\"\"\"\n",
    "    pi = math.pi\n",
    "    ln = math.log\n",
    "    MSE = np.mean((y_pred - y)**2)\n",
    "    return -(1/2)*(ln(2*pi*sigma2) + MSE/sigma2)"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statsmodels OLS documentation: https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_ll(model_name, task: PredictionTask) -> float:\n",
    "    x = task.A['x_known']\n",
    "    y = task.A['y_known']\n",
    "    x_out = task.A['x_to_predict']\n",
    "    fit_results = sm.OLS(y, design_matrix(model_name, x)).fit()\n",
    "    y_pred = fit_results.predict(design_matrix(model_name, x_out))\n",
    "    return log_likelihood(y_pred, task.B, fit_results.mse_resid)\n",
    "\n",
    "\n",
    "def design_matrix(model_name, x):\n",
    "    if model_name == \"Poly-4\":\n",
    "        X = np.column_stack([np.ones(len(x)), x, x**2, x**3, x**4])\n",
    "    elif model_name == \"Poly-3\":\n",
    "        X = np.column_stack([np.ones(len(x)), x, x**2, x**3])\n",
    "    elif model_name == \"Poly-2\":\n",
    "        X = np.column_stack([np.ones(len(x)), x, x**2])\n",
    "    elif model_name == \"Poly-1\":\n",
    "        X = np.column_stack([np.ones(len(x)), x])\n",
    "    elif model_name == \"Poly-0\":\n",
    "        X = np.column_stack([np.ones(len(x))])\n",
    "    else:\n",
    "        raise NotImplementedError(model_name)\n",
    "    return X\n",
    "\n",
    "\n",
    "sim_models = [\"Poly-0\", \"Poly-1\", \"Poly-2\", \"Poly-3\", \"Poly-4\"]"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "x_all = generate_x((0, 5), copies=1)\n",
    "fit_results4 = sm.OLS(\n",
    "    task_of_interest.A['y_known'],\n",
    "    design_matrix(\"Poly-4\", task_of_interest.A['x_known']),\n",
    ").fit()\n",
    "y4 = fit_results4.predict(design_matrix(\"Poly-4\", x_all))    \n",
    "y4_std = fit_results4.mse_resid**0.5\n",
    "plt.scatter(task_of_interest.A['x_known'], task_of_interest.A['y_known'], \n",
    "            label=\"Known data\", color=\"blue\", marker='s', s=10, alpha=0.1)\n",
    "plt.plot(x_all, y4, label=\"Poly-4\", color=\"gray\", linewidth=2)\n",
    "plt.plot(x_all, y4 + 1.645*y4_std, label=f\"Poly-4 90% CI\", color=\"gray\", linestyle='--', linewidth=1)\n",
    "plt.plot(x_all, y4 - 1.645*y4_std, color=\"gray\", linestyle='--', linewidth=1)\n",
    "plt.xlim(-0.075, 5.075)\n",
    "plt.ylim(-1.0, 1.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "cell-fig-poly4-predict"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "fit_results1 = sm.OLS(\n",
    "    task_of_interest.A['y_known'],\n",
    "    design_matrix(\"Poly-1\", task_of_interest.A['x_known']),\n",
    ").fit()\n",
    "y1 = fit_results1.predict(design_matrix(\"Poly-1\", x_all))\n",
    "y1_std = fit_results1.mse_resid**0.5\n",
    "plt.scatter(task_of_interest.A['x_known'], task_of_interest.A['y_known'], \n",
    "            label=\"Known data\", color=\"blue\", marker='s', s=10, alpha=0.1)\n",
    "plt.plot(x_all, y1, label=\"Poly-1\", color=\"gray\", linewidth=2)\n",
    "plt.plot(x_all, y1 + 1.645*y1_std, label=f\"Poly-1 90% CI\", color=\"gray\", linestyle='--', linewidth=1)\n",
    "plt.plot(x_all, y1 - 1.645*y1_std, color=\"gray\", linestyle='--', linewidth=1)\n",
    "plt.xlim(-0.075, 5.075)\n",
    "plt.ylim(-1.5, 1.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "cell-fig-poly1-predict"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Results"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "[np.float64(-2.870443608400252),\n",
       " np.float64(0.8788369626883851),\n",
       " np.float64(-18.63054717541598),\n",
       " np.float64(-4.984451316175962),\n",
       " np.float64(-9.054374407164836)]"
      ]
     }
    }
   ],
   "source": [
    "scores_single = [pclass_single.predictive_success(partial(predicted_ll, model_name)) for model_name in sim_models]\n",
    "scores_single"
   ],
   "id": "cell-15"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "[0.056673780037751864,\n",
       " 2.4080973700308568,\n",
       " 8.10692521752496e-09,\n",
       " 0.006843531932783001,\n",
       " 0.00011687864225465167]"
      ]
     }
    }
   ],
   "source": [
    "[math.exp(ll) for ll in scores_single]"
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_centrality(model_name, task):\n",
    "    \"\"\"Plot predicted line (over full 0-3.5 domain) over scatter plot of the _to_predict data\"\"\"\n",
    "    x_all = generate_x((0, 5), copies=1)\n",
    "    fit_results = sm.OLS(\n",
    "        task.A['y_known'],\n",
    "        design_matrix(model_name, task.A['x_known']),\n",
    "    ).fit()\n",
    "    y_pred = fit_results.predict(design_matrix(model_name, x_all))\n",
    "    y_std = fit_results.mse_resid**0.5\n",
    "    plt.scatter(task.A['x_known'], task.A['y_known'], label=\"Training Data\", \n",
    "                color=\"blue\", marker='s', s=10, alpha=0.1)\n",
    "    plt.scatter(task.A['x_to_predict'], task.B, label=\"Held-out Data\", \n",
    "                color=\"green\", marker='s', s=10, alpha=0.1)\n",
    "    plt.plot(x_all, y_pred, label=model_name, color=\"gray\", linewidth=2)\n",
    "    plt.plot(x_all, y_pred + 1.645*y_std, label=f\"{model_name} 90% CI\", color=\"gray\", linestyle='--', linewidth=1)\n",
    "    plt.plot(x_all, y_pred - 1.645*y_std, color=\"gray\", linestyle='--', linewidth=1)\n",
    "    plt.xlim(-0.075, 3.575)\n",
    "    plt.ylim(-0.1, 1.08)\n",
    "    plt.xticks([1, 2, 3])\n",
    "    # plt.yticks([0.2, .4, .6, 0.8, 1.0])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "cell-17"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "plot_predicted_centrality(\"Poly-4\", make_task((0, 2.5), (2.6, 3.5)))"
   ],
   "id": "cell-fig-poly4-eval"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "plot_predicted_centrality(\"Poly-1\", make_task((0, 2.5), (2.6, 3.5)))"
   ],
   "id": "cell-fig-poly1-eval"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate Prediction Class"
   ],
   "id": "cell-20"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10"
     ]
    },
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "[np.float64(-2.1386458322914335),\n",
       " np.float64(1.2209215151126325),\n",
       " np.float64(-21.46668435058918),\n",
       " np.float64(-2.831988084630039),\n",
       " np.float64(-11.741231148018695)]"
      ]
     }
    }
   ],
   "source": [
    "step = 0.1\n",
    "tasks = []\n",
    "for i in range(0, 10):\n",
    "    cal_end = round(3.4 - step * i, 1)\n",
    "    tasks.append(make_task((0, cal_end), (3.5, 3.5)))\n",
    "print(len(tasks))\n",
    "tasks.append(make_task((0, 2.5), (2.6, 3.4)))\n",
    "pclass = WeightedPredictionClass(tasks)\n",
    "scores = [pclass.predictive_success(partial(predicted_ll, model_name)) for model_name in sim_models]\n",
    "scores"
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "[0.1178142753356378,\n",
       " 3.3903105169322107,\n",
       " 4.754856797504306e-10,\n",
       " 0.05889564766842201,\n",
       " 7.95880935336731e-06]"
      ]
     }
    }
   ],
   "source": [
    "[math.exp(ll) for ll in scores]"
   ],
   "id": "cell-22"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gen_simulation(tasks, models):\n",
    "    \"\"\"Runs the simulation and returns the results.\"\"\"\n",
    "\n",
    "    results_dict = {}\n",
    "    for model_name in models:\n",
    "        results_dict[model_name] = {}\n",
    "        names = []\n",
    "        for i, task in enumerate(tasks):\n",
    "            name = str(i)\n",
    "            names.append(name)\n",
    "            results_dict[model_name][name] = {\n",
    "                \"ll_score\": predicted_ll(model_name, task)\n",
    "                #\"x\": x,  # Store x and y for plotting\n",
    "                #\"y\": y,\n",
    "            }\n",
    "    display(pd.DataFrame([[model] + [results_dict[model][range_name][\"ll_score\"] for range_name in names] for model in models]))\n",
    "    return results_dict"
   ],
   "id": "cell-23"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/html": [
       "\n",
       "</div>"
      ]
     }
    }
   ],
   "source": [
    "results_gen2 = run_gen_simulation(tasks, sim_models)"
   ],
   "id": "cell-24"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "array([1.17814275e-01, 3.39031052e+00, 4.75485680e-10, 5.88956477e-02,\n",
       "       7.95880935e-06])"
      ]
     }
    }
   ],
   "source": [
    "temp = np.exp(np.mean(np.array([[results_gen2[model][range_name][\"ll_score\"] for range_name in results_gen2[model]] for model in sim_models]), axis=1))\n",
    "temp"
   ],
   "id": "cell-25"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {
      "text/plain": [
       "array([3.47502905e-02, 1.00000000e+00, 1.40248416e-10, 1.73717562e-02,\n",
       "       2.34751635e-06])"
      ]
     }
    }
   ],
   "source": [
    "temp/temp[1]"
   ],
   "id": "cell-26"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
